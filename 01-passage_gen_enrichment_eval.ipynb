{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b098af9-9f80-45c2-89a5-4270676e6bee",
   "metadata": {},
   "source": [
    "# Operationalize product data and content enrichment using GenAI and AutoSxS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72c331-725b-4937-9852-f01992fac185",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This series of notebooks showcases an end-to-end workflow for improving product catalog data using Generative AI and MLOps. The core focus is to operationalize the process for enriching product descriptions, a key element for effective product discovery and recommendation systems.\n",
    "\n",
    "We begin in this notebook by enhancing product descriptions using the open-source GenAI model, Gemma. Next, we analyze and compare these results with those from Google's base models such as text-bison.\n",
    "\n",
    "The subsequent notebook delves into operationalizing this process, building a robust and scalable workflow orchestrated by Vertex AI Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49beb9ed-9cc2-4a11-b22c-a9762204f4f3",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "* Parameters, variables, and helper functions are defined\n",
    "* Import product feed data and define prompts\n",
    "* Deploy model A (OSS Gemma) and generate enriched product descriptions\n",
    "* Compare the quality of descriptions generated by Model A (Gemma) and Model B (text-bison-32k) using the AutoSxS evaluation framework\n",
    "* (optional) Provide human preference labels as ground truth data to review the evaluation with respect to human-aligned judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef501a4-11d5-4395-8abb-45811afb6bce",
   "metadata": {},
   "source": [
    "## Install additional packages\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0699e3c-514e-4be1-9ff7-b0524000b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install the packages\n",
    "# ! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "#                                  google-cloud-storage \\\n",
    "#                                  kfp \\\n",
    "#                                  google-cloud-pipeline-components \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716fcf5-dd3b-4190-98b8-d44d1f48e3bb",
   "metadata": {},
   "source": [
    "## Import Libraries & Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46cf4f2-ba98-480b-a4af-838508cf9cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "from google.cloud import aiplatform, language\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google_cloud_pipeline_components.preview import model_evaluation\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b7465-acf0-4257-9c7c-cf4f9f7668f4",
   "metadata": {},
   "source": [
    "### Set Parameters and Variables\n",
    "\n",
    "* `VERTEX_MODEL_GARDEN_GEMMA` - Requires accepting conditions and enabling on Vertex. See steps. (TBD) ###########\n",
    "* `PROJECT_ID`: The ID of your Google Cloud project where the pipeline and resources reside\n",
    "* `REGION`: The Google Cloud region where pipeline components are executed and resources are located\n",
    "* `BUCKET_URI`: The URI of the Google Cloud Storage bucket where data and pipeline artifacts are stored (e.g., \"gs://passage-gen-test\").\n",
    "* `BUCKET_NAME`: The name of the GCS bucket derived from the BUCKET_URI\n",
    "* `MODEL_RESOURCE`: The resource name of the baseline language model used for comparison in AutoSxS (e.g., \"publishers/google/models/text-bison-32k@002\").\n",
    "* `input_feed_data`: The GCS path to the input CSV file containing product data for generating descriptions\n",
    "* `evaluation_dataset_name`: The base name for the generated evaluation dataset files (without extension), used for both CSV and JSONL formats.\n",
    "* `SERVICE_ACCOUNT`: The service account used for running the pipeline components and accessing Google Cloud resources.\n",
    "* `DISPLAY_NAME`: The display name for the pipeline run, constructed using the ARTIFACT_REPO and a random string.\n",
    "* `DATASET_ID`: The ID of the BigQuery dataset where evaluation results or other data might be stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c4021e-f01f-4c18-b9eb-698b87f7d99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sandbox-401718\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}-passage-gen-test\"  # @param {type:\"string\"}\n",
    "BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"transient\")\n",
    "MODEL_BUCKET = os.path.join(BUCKET_URI, \"gemma\")\n",
    "MODEL_RESOURCE = \"publishers/google/models/text-bison-32k@002\"\n",
    "VERTEX_MODEL_GARDEN_GEMMA = \"https://storage.googleapis.com/vertex-ai/generative-ai/model-garden/gemma.tar.gz?GoogleAccessId=service-689411112969@gcp-sa-aiplatform.iam.gserviceaccount.com&amp;Expires=1711731130&amp;Signature=fQZ%252FULLGg0LlGl4ot%252Fw9xW1hhask%252F3y4Kb1eut3NNtMzStSpALR5MvGkMyh71uiMJci1c0j5DwNkcBv1q52YmD8WV2oq5yY8X5IQqqoHD9UeaC5jjor3fdmDEpvaFvL8Plk4DK4uW1X8kegkFLewQSdfUdDN19naRikyX6j34FGfr5MvfzyLXGMiQ483DgsLaIXiamDMjMOpScFRQKWGxUNgwls3lq%252Fv7vnVjbrdTll2Jzayv51wulMDNcd7EwYbIa9Dc5GFdmE8C07cTa5y84RTA1G%252FAC9TX5mkfxB0HMqUgT8Xkh7%252FYDpDN5kB5IFiO0NFK0z0AWsCmkvUG1VHhQ%253D%253D\"  # @param {type:\"string\", isTemplate:true} #HTTP address\n",
    "\n",
    "SERVICE_ACCOUNT = (\n",
    "    \"757654702990-compute@developer.gserviceaccount.com\"  # @param {type:\"string\"}\n",
    ")\n",
    "input_feed_data = \"gs://passage-gen-test/FeedGen-Input-Feed.csv\" # @param {type:\"string\"}\n",
    "evaluation_dataset_name = \"evaluation_dataset\"# @param {type:\"string\"}\n",
    "\n",
    "DATASET_ID = \"passage_gen_autosxs\"\n",
    "BQ_TABLE_EVAL = f\"{DATASET_ID}.eval_table\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98122fe8-be45-4062-814e-58b426709a34",
   "metadata": {},
   "source": [
    "**Only if your bucket doesn't already exist:** Run the following cell to create your Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c5a56d-b2c6-4e1b-af9e-f79ecce6c98d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://sandbox-401718-passage-gen-test/...\n"
     ]
    }
   ],
   "source": [
    "# ! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf02981-627f-4248-a83f-c1e782183701",
   "metadata": {},
   "source": [
    "## Import data set\n",
    "\n",
    "The 'Input Feed' data is based on a collection of 1,000-row random sample of data from the public BigQuery dataset 'theLook eCommerce'. The data including text and enriched attributes was generated by [FeedGen](https://github.com/google-marketing-solutions/feedgen) and was extracted as a CSV from the FeedGen [input feed - template sheet](https://docs.google.com/spreadsheets/d/19eKTJrbZaUfipAvL5ZQmq_hoxEbLQIlDqURKFJA2OBU/edit#gid=1661242997).\n",
    "\n",
    "For the purposes of this work, only the first 50 rows are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cec610f-fb5b-45e9-a1f3-b56b29434ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Category</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2480</td>\n",
       "      <td>ASICS Women's Performance Running Capri Tight</td>\n",
       "      <td>ASICS Women's Performance Running Capri Tight,...</td>\n",
       "      <td>ASICS</td>\n",
       "      <td>Women's</td>\n",
       "      <td>Active</td>\n",
       "      <td>S</td>\n",
       "      <td>White</td>\n",
       "      <td>Cotton, Polyester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21084</td>\n",
       "      <td>Agave Men's Waterman Relaxed Grey Jean</td>\n",
       "      <td>Agave Men's Waterman Relaxed Grey Jean, Relaxe...</td>\n",
       "      <td>Agave</td>\n",
       "      <td>Men's</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>33x30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27569</td>\n",
       "      <td>2XU Men's Swim Compression Long Sleeve Top</td>\n",
       "      <td>2XU Men's Swim Compression Long Sleeve Top, Li...</td>\n",
       "      <td>2XU</td>\n",
       "      <td>Men's</td>\n",
       "      <td>Swim</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PWX Fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8089</td>\n",
       "      <td>(6249-2) Smart Satin Evening Suit with Flute S...</td>\n",
       "      <td>Smart Satin Evening Suit with Flute Skirt Beig...</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Women's</td>\n",
       "      <td>Suits</td>\n",
       "      <td>L</td>\n",
       "      <td>Beige</td>\n",
       "      <td>Satin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Seven7 Women's Long Sleeve Stripe Belted Top</td>\n",
       "      <td>Seven7 Women's Long Sleeve Stripe Belted Top, ...</td>\n",
       "      <td>Seven7</td>\n",
       "      <td>Women's</td>\n",
       "      <td>Tops &amp; Tees</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item ID                                              Title  \\\n",
       "0     2480      ASICS Women's Performance Running Capri Tight   \n",
       "1    21084             Agave Men's Waterman Relaxed Grey Jean   \n",
       "2    27569         2XU Men's Swim Compression Long Sleeve Top   \n",
       "3     8089  (6249-2) Smart Satin Evening Suit with Flute S...   \n",
       "4        1       Seven7 Women's Long Sleeve Stripe Belted Top   \n",
       "\n",
       "                                         Description   Brand   Gender  \\\n",
       "0  ASICS Women's Performance Running Capri Tight,...   ASICS  Women's   \n",
       "1  Agave Men's Waterman Relaxed Grey Jean, Relaxe...   Agave    Men's   \n",
       "2  2XU Men's Swim Compression Long Sleeve Top, Li...     2XU    Men's   \n",
       "3  Smart Satin Evening Suit with Flute Skirt Beig...     Ice  Women's   \n",
       "4  Seven7 Women's Long Sleeve Stripe Belted Top, ...  Seven7  Women's   \n",
       "\n",
       "      Category   Size  Color           Material  \n",
       "0       Active      S  White  Cotton, Polyester  \n",
       "1        Jeans  33x30    NaN              Denim  \n",
       "2         Swim      M    NaN         PWX Fabric  \n",
       "3        Suits      L  Beige              Satin  \n",
       "4  Tops & Tees      M  Black                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(input_feed_data) \\\n",
    "      .drop(['Link', 'Image Link'], axis=1) \\\n",
    "      .head(50)\n",
    "\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e3ac3-2c54-49b3-a93c-50902a6fd883",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set-up Prompts\n",
    "\n",
    "Product descriptions are generated using a prompt inspired by [FeedGen](https://github.com/google-marketing-solutions/feedgen). This prompt also acts as a reference point for evaluating the quality of the descriptions during model comparisons. These prompts are dynamic and utilize information provided from each product entry in the input feed dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229cfec9-5f20-49b7-b4a8-00f7334f5240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "def prompt_func(prompt_input: str):\n",
    "    \"\"\"Prompts designed to enrich Product description information\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "        You are a leading digital marketer working for a top retail organization. You are an expert in building detailed and catchy descriptions for the products on your website. \n",
    "\n",
    "        Context: {prompt_input}\n",
    "\n",
    "        Generate ONLY the product description in English that highlights the product's features using the above \"Context\" information. \n",
    "        If you find a \"description\" in the given \"Context\", do NOT reuse it, but make sure you describe any features listed within it in more detail. \n",
    "        Do NOT repeat sentences. The generated description should strictly be about the provided product. \n",
    "        Correct product type, number of items contained in the the product as well as product features such as color should be followed. \n",
    "        Any product features that are not present in the input should not be present in the generated description.\n",
    "        Hyperbolic text, over promising or guarantees are to be avoided.\n",
    "        The generated description should be at least 50 words long, preferably at least 150. \n",
    "        The generated description MUST NOT use special characters or any Markdown or JSON syntax. \n",
    "\n",
    "        New Detailed Product Description:\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd415c2b-ed63-45e9-aab5-e912f63343ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gemma deployment\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str) -> str:\n",
    "    \"\"\"Gets the job name with date time when triggering deployment jobs.\"\"\"\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def deploy_model_vllm(\n",
    "    model_name: str,\n",
    "    model_id: str,\n",
    "    service_account: str,\n",
    "    machine_type: str = \"g2-standard-12\",\n",
    "    accelerator_type: str = \"NVIDIA_L4\",\n",
    "    accelerator_count: int = 1,\n",
    "    max_model_len: int = 8192,\n",
    "    dtype: str = \"bfloat16\",\n",
    ") -> Tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
    "    \"\"\"Deploys models with vLLM on GPU in Vertex AI.\"\"\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "\n",
    "    vllm_args = [\n",
    "        \"--host=0.0.0.0\",\n",
    "        \"--port=7080\",\n",
    "        f\"--model={model_id}\",\n",
    "        f\"--tensor-parallel-size={accelerator_count}\",\n",
    "        \"--swap-space=16\",\n",
    "        \"--gpu-memory-utilization=0.9\",\n",
    "        f\"--max-model-len={max_model_len}\",\n",
    "        f\"--dtype={dtype}\",\n",
    "        \"--disable-log-stats\",\n",
    "    ]\n",
    "\n",
    "    env_vars = {\n",
    "        \"MODEL_ID\": model_id,\n",
    "    }\n",
    "    # if HF_TOKEN:\n",
    "    #     env_vars[\"HF_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=VLLM_DOCKER_URI,\n",
    "        serving_container_command=[\"python\", \"-m\", \"vllm.entrypoints.api_server\"],\n",
    "        serving_container_args=vllm_args,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/generate\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=env_vars,\n",
    "        serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n",
    "        serving_container_deployment_timeout=7200,\n",
    "    )\n",
    "\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=service_account,\n",
    "        sync=True,\n",
    "        enable_access_logging=True,\n",
    "    )\n",
    "    return model, endpoint\n",
    "\n",
    "## UUID\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "UUID = generate_uuid()\n",
    "\n",
    "\n",
    "def save_csv_gcs(BUCKET_NAME: str, evaluation_dataset_name: str):\n",
    "    \"\"\"\n",
    "    Saves a CSV file to a Google Cloud Storage bucket.\n",
    "\n",
    "    Args:\n",
    "        BUCKET_NAME (str):  The name of the GCS bucket (excluding the 'gs://' prefix).\n",
    "        evaluation_dataset_name (str):  The filename (without extension) to use for the saved CSV.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # save to GCS\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET_NAME[5:])\n",
    "    blob = bucket.blob(f\"data/{evaluation_dataset_name}.csv\")\n",
    "    blob.upload_from_filename(f\"{evaluation_dataset_name}.csv\")\n",
    "\n",
    "    print(f\"File uploaded to cloud storage in {BUCKET_NAME}/data/{evaluation_dataset_name}.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def save_jsonl_gcs(BUCKET_NAME: str, evaluation_dataset_name: str):\n",
    "    \"\"\"\n",
    "    Saves a JSON Lines (.jsonl) file to a Google Cloud Storage bucket.\n",
    "\n",
    "    Args:\n",
    "        BUCKET_NAME (str):  The name of the GCS bucket (excluding the 'gs://' prefix).\n",
    "        evaluation_dataset_name (str):  The filename (without extension) to use for the saved JSONL file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # save to GCS \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET_NAME[5:])\n",
    "    blob = bucket.blob(f\"data/{evaluation_dataset_name}.jsonl\")\n",
    "    blob.upload_from_filename(f\"{evaluation_dataset_name}.jsonl\")\n",
    "\n",
    "    print(f\"File uploaded to cloud storage in {BUCKET_NAME}/data/{evaluation_dataset_name}.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bc9d4-84ef-432e-9e52-eff2942acffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Gemma and generate responses\n",
    "\n",
    "Deploy Gemma on GPU using [vLLM](https://github.com/vllm-project/vllm), the state-of-the-art open source LLM serving solution on GPU.\n",
    "\n",
    "Note: to use Gemma, users will need to click the agreement in Vertex AI Model Garden, and get the URL to Gemma model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ab604c-7015-4581-96a9-37d3db85f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI API.\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e3654-dba0-4b15-ba3a-e8e47c5b0469",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download Gemma, Extract locally, and save to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d2fa61-901e-4af0-92f2-53f06a5e7cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0gemma/\n",
      "gemma/gemma-2b-it/\n",
      "gemma/gemma-2b-it/config.json\n",
      "gemma/gemma-2b-it/tokenizer.model\n",
      "gemma/gemma-2b-it/generation_config.json\n",
      "gemma/gemma-2b-it/model.safetensors.index.json\n",
      "gemma/gemma-2b-it/model-00001-of-00002.safetensors\n",
      "  0 32.7G    0  297M    0     0  49.6M      0  0:11:14  0:00:05  0:11:09 52.0M^C\n",
      "Copying file://./gemma/gemma/gemma-2b-it/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./gemma/gemma/gemma-2b-it/generation_config.json [Content-Type=application/json]...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    VERTEX_MODEL_GARDEN_GEMMA\n",
    "), \"Please click the agreement of Gemma in Vertex AI Model Garden, and get the URL to Gemma model artifacts.\"\n",
    "\n",
    "# Only use the last part in case a full command is pasted.\n",
    "signed_url = VERTEX_MODEL_GARDEN_GEMMA.split(\" \")[-1].strip('\"')\n",
    "\n",
    "! mkdir -p ./gemma\n",
    "! curl -X GET \"{signed_url}\" | tar -xzvf - -C ./gemma/\n",
    "! gsutil -m cp -R ./gemma/* {MODEL_BUCKET}\n",
    "\n",
    "model_path_prefix = MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb43674-3380-4616-b803-bcd5a768dc27",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e66dd942-65cd-463c-9b43-17d0a0ce9f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Serving docker images.\n",
    "VLLM_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9caf6a2-57c7-40fc-9249-beffc4dd9330",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy Gemma models with vLLM on GPU\n",
    "\n",
    "vLLM is a high-performance library for serving large language models (LLMs) on GPUs, offering optimizations like paged attention and continuous batching. The following demonstrates deploying the Gemma LLM model using the vLLM serving library. Users can consider various GPU configurations for optimal performance and cost efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd56e92e-aa42-4cbf-8b38-02f9d6dd0567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemma-7b\"  # @param [\"gemma-2b\", \"gemma-2b-it\", \"gemma-7b\", \"gemma-7b-it\"]\n",
    "model_id = os.path.join(MODEL_BUCKET, MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da78165-18e5-4803-98a2-7b3f11aaa57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/757654702990/locations/us-central1/endpoints/7117910623756746752/operations/7910200595150012416\n",
      "Endpoint created. Resource name: projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/757654702990/locations/us-central1/endpoints/7117910623756746752')\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/757654702990/locations/us-central1/models/1805751036040708096/operations/668412394338254848\n",
      "Model created. Resource name: projects/757654702990/locations/us-central1/models/1805751036040708096@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/757654702990/locations/us-central1/models/1805751036040708096@1')\n",
      "Deploying model to Endpoint : projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n",
      "Deploy Endpoint model backing LRO: projects/757654702990/locations/us-central1/endpoints/7117910623756746752/operations/4379378487291543552\n",
      "Endpoint model deployed. Resource name: projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n"
     ]
    }
   ],
   "source": [
    "# Finds Vertex AI prediction supported accelerators and regions in\n",
    "# https://cloud.google.com/vertex-ai/docs/predictions/configure-compute.\n",
    "\n",
    "if \"2b\" in MODEL_ID:\n",
    "    # Sets 1 L4 (24G) to deploy Gemma 2B models.\n",
    "    machine_type = \"g2-standard-8\"\n",
    "    accelerator_type = \"NVIDIA_L4\"\n",
    "    accelerator_count = 1\n",
    "    vllm_dtype = \"bfloat16\"\n",
    "else:\n",
    "    # Sets 1 L4 (24G) to deploy Gemma 7B models.\n",
    "    machine_type = \"g2-standard-12\"\n",
    "    accelerator_type = \"NVIDIA_L4\"\n",
    "    accelerator_count = 1\n",
    "    vllm_dtype = \"bfloat16\"\n",
    "\n",
    "# Alternative hardware configurations:\n",
    "\n",
    "# Sets 1 A100 (40G) to deploy Gemma 2B and Gemma 7B models.\n",
    "# machine_type = \"a2-highgpu-1g\"\n",
    "# accelerator_type = \"NVIDIA_TESLA_A100\"\n",
    "# accelerator_count = 1\n",
    "# vllm_dtype = \"bfloat16\"\n",
    "\n",
    "# Sets 1 T4 (16G) to deploy Gemma 2B models.\n",
    "machine_type = \"g2-standard-96\"\n",
    "accelerator_type = \"NVIDIA_L4\"\n",
    "accelerator_count = 8\n",
    "vllm_dtype = \"float32\"\n",
    "\n",
    "# Note that a larger max_model_len will require more GPU memory.\n",
    "max_model_len = 2048\n",
    "\n",
    "model_vllm, endpoint_vllm = deploy_model_vllm(\n",
    "    model_name=get_job_name_with_datetime(prefix=\"gemma-serve-vllm\"),\n",
    "    model_id=model_id,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    max_model_len=max_model_len,\n",
    "    dtype=vllm_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b76f66-08ff-4993-9ec9-ddb3e2f7e4e3",
   "metadata": {},
   "source": [
    "### Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bf0f894-bc85-4454-bcff-55dea29ab887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is a car?\n",
      "Output:\n",
      " Itâ€™s a machine that can carry people and goods from one place to another, and is usually powered by an internal combustion engine running on petrol or diesel. The internal combustion engine is connected to the transmission and drives the wheels, which are connected to\n"
     ]
    }
   ],
   "source": [
    "# # Loads an existing endpoint instance using the endpoint name:\n",
    "# endpoint_name = \"\"  # @param {type:\"string\"}\n",
    "# aip_endpoint_name = (\n",
    "#     f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{endpoint_name}\"\n",
    "# )\n",
    "# endpoint_vllm = aiplatform.Endpoint(aip_endpoint_name)\n",
    "\n",
    "instances = [\n",
    "    {\n",
    "        \"prompt\": \"What is a car?\",\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 1.0,\n",
    "        \"top_p\": 1.0,\n",
    "        \"top_k\": 10,\n",
    "        \"raw_response\": False,\n",
    "    },\n",
    "]\n",
    "response = endpoint_vllm.predict(instances=instances)\n",
    "\n",
    "prediction = response.predictions[0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8022839-100f-4306-a6cd-e3ba5574ae19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run predictions\n",
    "\n",
    "Generates a product description based on provided context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fade0b6-4fef-4b9f-9014-002d07ba7b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = []\n",
    "\n",
    "# Generate description for each product row\n",
    "for index, row in df.iterrows():\n",
    "    if index % 5 == 0:\n",
    "        print(\"Processing row:\", index+1)\n",
    "\n",
    "    # prompt_input = row.result\n",
    "    prompt_input = row.to_dict()\n",
    "    prompt = prompt_func(prompt_input)\n",
    "    instances = [\n",
    "        {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 0.5,\n",
    "            \"top_k\": 10,\n",
    "            \"raw_response\": True,\n",
    "        },\n",
    "    ]\n",
    "    response = endpoint_vllm.predict(instances=instances)\n",
    "    prediction = response.predictions[0]\n",
    "\n",
    "    # Append results\n",
    "    eval_df.append(\n",
    "        {\n",
    "            \"prompt_id\": prompt_input,\n",
    "            \"prompt\": prompt,\n",
    "            \"response_a\": prediction,\n",
    "            \"name\": prompt_input[\"Title\"],\n",
    "            \"id\": prompt_input[\"Item ID\"],\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecccc1-05a8-443b-92cc-b95d05e00505",
   "metadata": {},
   "source": [
    "### Save responses and prompts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08a11586-eb28-40a6-a624-6f48c7bcb74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to cloud storage in gs://sandbox-401718-passage-gen-test/data/evaluation_dataset.csv\n",
      "File uploaded to cloud storage in gs://sandbox-401718-passage-gen-test/data/evaluation_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "eval_df_ = pd.DataFrame(eval_df)\n",
    "\n",
    "# Syntax cleanup \n",
    "def remove_newlines(text):\n",
    "    return text.replace('\\n', ' ')\n",
    "\n",
    "eval_df_.loc[:, 'response_a'] = eval_df_['response_a'].apply(remove_newlines)\n",
    "\n",
    "# Save CSV\n",
    "eval_df_.to_csv(f\"{evaluation_dataset_name}.csv\", index=False)\n",
    "save_csv_gcs(BUCKET_NAME, evaluation_dataset_name)\n",
    "\n",
    "# Save JSON\n",
    "eval_df_.to_json(f\"{evaluation_dataset_name}.jsonl\", orient=\"records\", lines=True)\n",
    "save_jsonl_gcs(BUCKET_NAME, evaluation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba86e7ee-1820-471c-92ab-04fac817e6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Item ID': 2480, 'Title': 'ASICS Women's Perf...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>ASICS Women's Performance Running Ca...</td>\n",
       "      <td>ASICS Women's Performance Running Capri Tight</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'Item ID': 21084, 'Title': 'Agave Men's Water...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Agave Men's Waterman Relaxed Grey Je...</td>\n",
       "      <td>Agave Men's Waterman Relaxed Grey Jean</td>\n",
       "      <td>21084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'Item ID': 27569, 'Title': '2XU Men's Swim Co...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>2XU Men's Swim Compression Long Slee...</td>\n",
       "      <td>2XU Men's Swim Compression Long Sleeve Top</td>\n",
       "      <td>27569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'Item ID': 8089, 'Title': '(6249-2) Smart Sat...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Smart Satin Evening Suit with Flute ...</td>\n",
       "      <td>(6249-2) Smart Satin Evening Suit with Flute S...</td>\n",
       "      <td>8089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'Item ID': 1, 'Title': 'Seven7 Women's Long S...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Seven7 Women's Long Sleeve Stripe Be...</td>\n",
       "      <td>Seven7 Women's Long Sleeve Stripe Belted Top</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prompt_id  \\\n",
       "0  {'Item ID': 2480, 'Title': 'ASICS Women's Perf...   \n",
       "1  {'Item ID': 21084, 'Title': 'Agave Men's Water...   \n",
       "2  {'Item ID': 27569, 'Title': '2XU Men's Swim Co...   \n",
       "3  {'Item ID': 8089, 'Title': '(6249-2) Smart Sat...   \n",
       "4  {'Item ID': 1, 'Title': 'Seven7 Women's Long S...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  \\n        You are a leading digital marketer w...   \n",
       "1  \\n        You are a leading digital marketer w...   \n",
       "2  \\n        You are a leading digital marketer w...   \n",
       "3  \\n        You are a leading digital marketer w...   \n",
       "4  \\n        You are a leading digital marketer w...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0            ASICS Women's Performance Running Ca...   \n",
       "1            Agave Men's Waterman Relaxed Grey Je...   \n",
       "2            2XU Men's Swim Compression Long Slee...   \n",
       "3            Smart Satin Evening Suit with Flute ...   \n",
       "4            Seven7 Women's Long Sleeve Stripe Be...   \n",
       "\n",
       "                                                name     id  \n",
       "0      ASICS Women's Performance Running Capri Tight   2480  \n",
       "1             Agave Men's Waterman Relaxed Grey Jean  21084  \n",
       "2         2XU Men's Swim Compression Long Sleeve Top  27569  \n",
       "3  (6249-2) Smart Satin Evening Suit with Flute S...   8089  \n",
       "4       Seven7 Women's Long Sleeve Stripe Belted Top      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f134b41-8794-4814-a941-1f70c01e11a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run AutoSxS\n",
    "\n",
    "Compare Google published models such as text-bison (Model A) to the responses generated by Gemma (model B).\n",
    "\n",
    "The expected parameters are: `inference_instruction` (details on how to perform a task) and `inference_context` (content to reference to perform the task). As an example, `{'inference_context': {'column': 'my_prompt'}}` uses the evaluation dataset's `prompt` column for the AutoRater's context.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b848d5-7213-49ce-9693-961a624f3b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_uri = 'pipeline.yaml'\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=model_evaluation.autosxs_pipeline,\n",
    "    package_path=template_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5754965d-c283-41b6-b79d-b5926117d42e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/examples-resp-model-full-32k-3qt9dw7z?project=757654702990\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-3qt9dw7z\n"
     ]
    }
   ],
   "source": [
    "UUID = generate_uuid()\n",
    "display_name = f\"examples-resp-model-full-32k-{UUID}\"\n",
    "context_column = \"name\"\n",
    "question_column = \"prompt\"\n",
    "response_column = \"response_a\"\n",
    "model_prompt = \"prompt\"\n",
    "model_resource = MODEL_RESOURCE\n",
    "\n",
    "parameters = {\n",
    "    \"evaluation_dataset\": \"gs://passage-gen-test/data/evaluation_dataset.jsonl\",\n",
    "    \"id_columns\": [question_column],\n",
    "    \"autorater_prompt_parameters\": {\n",
    "        \"inference_context\": {\"column\": context_column},\n",
    "        \"inference_instruction\": {\"column\": question_column},\n",
    "    },\n",
    "    \"task\": \"question_answering@001\",\n",
    "    \"model_a\": model_resource,\n",
    "    \"model_a_prompt_parameters\": {\"prompt\": {\"column\": model_prompt}},\n",
    "    \"response_column_b\": response_column,\n",
    "}\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n",
    "job = aiplatform.PipelineJob(\n",
    "    job_id=display_name,\n",
    "    display_name=display_name,\n",
    "    pipeline_root=os.path.join(BUCKET_URI, display_name),\n",
    "    template_path=template_uri,\n",
    "    parameter_values=parameters,\n",
    "    enable_caching=False,\n",
    ")\n",
    "job.run(sync=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f417d0-dcfb-4404-b405-34ccdde44ef8",
   "metadata": {},
   "source": [
    "### Fetch the AutoSxS judgments and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dfb8a6f-f384-4867-99ae-5f1af4cc4ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>inference_instruction</th>\n",
       "      <th>inference_context</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>choice</th>\n",
       "      <th>explanation</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>ASICS Women's Performance Running Capri Tight</td>\n",
       "      <td>Unleash your athletic potential with our ASIC...</td>\n",
       "      <td>ASICS Women's Performance Running Ca...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (B) is grounded and fully answers the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Unisex Chequered Arab Arafat Shemagh Kafiyah D...</td>\n",
       "      <td>Discover our stunning collection of 17 gorgeo...</td>\n",
       "      <td>\"This unisex chequered Arab Arafat s...</td>\n",
       "      <td>B</td>\n",
       "      <td>Both responses are well-written and capture th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>RetroFit Men's Long Sleeve Pullover Hoodie Swe...</td>\n",
       "      <td>Slip into cozy comfort with our RetroFit Men'...</td>\n",
       "      <td>\"RetroFit Men's Long Sleeve Pullover...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (A) provides a detailed description o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>City Hunter Soft Nylon Russian/Trapper/Trooper...</td>\n",
       "      <td>Stay warm and protected from the harsh winter...</td>\n",
       "      <td>City Hunter Soft Nylon Russian/Trapp...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (A) is well-written and provides addi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Rago Pull On Open Girdle</td>\n",
       "      <td>Experience unparalleled support and comfort w...</td>\n",
       "      <td>Rago Pull On Open Girdle, Firm contr...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (A) provides a detailed description o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n        You are a leading digital marketer w...   \n",
       "1  \\n        You are a leading digital marketer w...   \n",
       "2  \\n        You are a leading digital marketer w...   \n",
       "3  \\n        You are a leading digital marketer w...   \n",
       "4  \\n        You are a leading digital marketer w...   \n",
       "\n",
       "                               inference_instruction  \\\n",
       "0  \\n        You are a leading digital marketer w...   \n",
       "1  \\n        You are a leading digital marketer w...   \n",
       "2  \\n        You are a leading digital marketer w...   \n",
       "3  \\n        You are a leading digital marketer w...   \n",
       "4  \\n        You are a leading digital marketer w...   \n",
       "\n",
       "                                   inference_context  \\\n",
       "0      ASICS Women's Performance Running Capri Tight   \n",
       "1  Unisex Chequered Arab Arafat Shemagh Kafiyah D...   \n",
       "2  RetroFit Men's Long Sleeve Pullover Hoodie Swe...   \n",
       "3  City Hunter Soft Nylon Russian/Trapper/Trooper...   \n",
       "4                           Rago Pull On Open Girdle   \n",
       "\n",
       "                                          response_a  \\\n",
       "0   Unleash your athletic potential with our ASIC...   \n",
       "1   Discover our stunning collection of 17 gorgeo...   \n",
       "2   Slip into cozy comfort with our RetroFit Men'...   \n",
       "3   Stay warm and protected from the harsh winter...   \n",
       "4   Experience unparalleled support and comfort w...   \n",
       "\n",
       "                                          response_b choice  \\\n",
       "0            ASICS Women's Performance Running Ca...      A   \n",
       "1            \"This unisex chequered Arab Arafat s...      B   \n",
       "2            \"RetroFit Men's Long Sleeve Pullover...      A   \n",
       "3            City Hunter Soft Nylon Russian/Trapp...      A   \n",
       "4            Rago Pull On Open Girdle, Firm contr...      A   \n",
       "\n",
       "                                         explanation  confidence  \n",
       "0  Response (B) is grounded and fully answers the...           1  \n",
       "1  Both responses are well-written and capture th...           1  \n",
       "2  Response (A) provides a detailed description o...           1  \n",
       "3  Response (A) is well-written and provides addi...           1  \n",
       "4  Response (A) provides a detailed description o...           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use an existing pipeline, override job using the line below.\n",
    "# job = aiplatform.PipelineJob.get('projects/[PROJECT_NUMBER]/locations/[REGION]/pipelineJobs/[PIPELINE_RUN_NAME]')\n",
    "\n",
    "for details in job.task_details:\n",
    "    if details.task_name == \"online-evaluation-pairwise\":\n",
    "        break\n",
    "\n",
    "# Judgments\n",
    "judgements_uri = details.outputs[\"judgments\"].artifacts[0].uri\n",
    "judgements_df = pd.read_json(judgements_uri, lines=True)\n",
    "judgements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f82c6947-e7bd-4765-b0db-50897d01dd20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autosxs_model_a_win_rate</th>\n",
       "      <th>autosxs_model_b_win_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   autosxs_model_a_win_rate  autosxs_model_b_win_rate\n",
       "0                      0.98                      0.02"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate Metrics\n",
    "for details in job.task_details:   #full job details\n",
    "    if details.task_name == \"model-evaluation-text-generation-pairwise\":\n",
    "        break\n",
    "pd.DataFrame([details.outputs[\"autosxs_metrics\"].artifacts[0].metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a97f9213-bc5b-4912-baff-a96a26bd3681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artifacts {\n",
       "  name: \"projects/757654702990/locations/us-central1/metadataStores/default/artifacts/13809795646850762148\"\n",
       "  display_name: \"autosxs_metrics\"\n",
       "  etag: \"1715016211631\"\n",
       "  create_time {\n",
       "    seconds: 1715016087\n",
       "    nanos: 568000000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1715016211\n",
       "    nanos: 631000000\n",
       "  }\n",
       "  state: LIVE\n",
       "  schema_title: \"system.Metrics\"\n",
       "  schema_version: \"0.0.1\"\n",
       "  metadata {\n",
       "    fields {\n",
       "      key: \"autosxs_model_b_win_rate\"\n",
       "      value {\n",
       "        number_value: 0.02\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"autosxs_model_a_win_rate\"\n",
       "      value {\n",
       "        number_value: 0.98\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details.outputs[\"autosxs_metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39dd7d-9534-4742-8817-6954de494803",
   "metadata": {},
   "source": [
    "### Investigate AutoSxS comparison judgements and explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "065f97e0-463c-4593-9f3c-606e3001c021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response A:  Hit the beach in style with the Billabong Gettin Jiggy Board Shorts, a pair of vibrant and functional water shorts designed for men who love to make a statement. These board shorts come in a pack of one and boast a captivating all-over tie-dye print in shades of orange, sure to turn heads wherever you go.\n",
      "\n",
      "Made with water-repellent fabric, these shorts dry quickly, ensuring you stay comfortable and fresh even after taking a dip in the ocean or lounging by the\n",
      "\n",
      "Response B:           \"Billabong Gettin Jiggy Board Short - Men's, 5-inch water shorts with all-over tie-dye print, Elastic waistband with drawstring, Water-repellent fabric for quick drying, Comfortable and stylish\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "Explanation: Response (B) is a copy of the description provided in the context. Response (A) provides a detailed description of the product, highlighting its features such as the all-over tie-dye print, water-repellent fabric for quick drying, and comfortable fit. It also uses persuasive language to create a desire for the product.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Response A: {judgements_df['response_a'][6]}\\n\")\n",
    "print(f\"Response B: {judgements_df['response_b'][6]}\\n\")\n",
    "print(f\"Explanation: {judgements_df['explanation'][6]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a9f352-7b75-4c68-aed8-56acebee8224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to cloud storage in gs://sandbox-401718-passage-gen-test/data/judgements_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Judgements to GCS\n",
    "judgements_df.to_csv(\"judgements_df.csv\", index=False)\n",
    "save_csv_gcs(BUCKET_NAME, \"judgements_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb92fb3-ff2b-4755-9b50-2312d4d0f2f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (optional) Ground Truth human preferences\n",
    "\n",
    "Users have the option to specify a column that indicates the preference between pre-generated responses. Human alignment is used to build trust in the autorater by providing metrics that quantify the agreement between AutoSXS and the human judgment, building trust in the autorater's ability to accurately judge the responses. By quantifying the agreement between the model's choices and human preferences, users can confidently rely on AutoSXS to accurately identify the most suitable model to generate the best product descriptions for the product catalog.\n",
    "\n",
    "![human-pref.png](./imgs/check-alignment.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19c5fce3-e42e-487e-ae94-6fe2a972c45d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to cloud storage in gs://sandbox-401718-passage-gen-test/data/evaluation_dataset_human_pref.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Inspect\n",
    "eval_df_ = pd.read_csv(f\"{BUCKET_NAME}/data/{evaluation_dataset_name}.csv\")\n",
    "eval_df_[\"human_preferences\"] = \"A\"\n",
    "\n",
    "# Judgements\n",
    "judgements_df = pd.read_csv(f\"{BUCKET_NAME}/data/judgements_df.csv\")\n",
    "eval_df_human_pref = pd.merge(eval_df_, judgements_df, on='prompt', how='left')\n",
    "\n",
    "# Save JSON to GCS\n",
    "eval_df_human_pref.to_json(\"evaluation_dataset_human_pref.jsonl\", orient=\"records\", lines=True)\n",
    "save_jsonl_gcs(BUCKET_NAME, \"evaluation_dataset_human_pref\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a8296-b3ba-4190-be15-05d119fc8502",
   "metadata": {},
   "source": [
    "### Run AutoSxS w/ Human Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e651c937-8451-4a09-88a0-569ca5f8f758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_uri = 'pipeline.yaml'\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=model_evaluation.autosxs_pipeline,\n",
    "    package_path=template_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46be985e-e60e-44c3-8958-c8b2a4e8b746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a?project=757654702990\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/757654702990/locations/us-central1/pipelineJobs/examples-resp-model-full-32k-human-pref-sdazv6of-pref-a\n"
     ]
    }
   ],
   "source": [
    "UUID = generate_uuid()\n",
    "display_name = f\"examples-resp-model-full-32k-human-pref-{UUID}-pref-a\"\n",
    "context_column = \"name\"\n",
    "question_column = \"prompt\"\n",
    "response_column_a = \"response_a_y\"\n",
    "response_column_b = \"response_b\"\n",
    "human_preference_column = \"human_preferences\"\n",
    "\n",
    "parameters = {\n",
    "    \"evaluation_dataset\": f\"{BUCKET_NAME}/data/evaluation_dataset_human_pref.jsonl\",\n",
    "    \"id_columns\": [question_column],\n",
    "    \"autorater_prompt_parameters\": {\n",
    "        \"inference_context\": {\"column\": context_column},\n",
    "        \"inference_instruction\": {\"column\": question_column},\n",
    "    },\n",
    "    \"task\": \"question_answering@001\",\n",
    "    \"response_column_a\": response_column_a,\n",
    "    \"response_column_b\": response_column_b,\n",
    "    \"human_preference_column\": human_preference_column,\n",
    "\n",
    "}\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n",
    "job = aiplatform.PipelineJob(\n",
    "    job_id=display_name,\n",
    "    display_name=display_name,\n",
    "    pipeline_root=os.path.join(BUCKET_URI, display_name),\n",
    "    template_path=template_uri,\n",
    "    parameter_values=parameters,\n",
    "    enable_caching=False,\n",
    ")\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fdf2425-1524-4ce7-bf8f-b683e4045575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>inference_instruction</th>\n",
       "      <th>inference_context</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>choice</th>\n",
       "      <th>explanation</th>\n",
       "      <th>confidence</th>\n",
       "      <th>human_preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Nautica Men's Castaway Stripe Hoodie</td>\n",
       "      <td>Slip into effortless style with our Nautica M...</td>\n",
       "      <td>\"Nautica Men's Castaway Stripe Hoodi...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (B) is a repetition of the input desc...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>Unisex Chequered Arab Arafat Shemagh Kafiyah D...</td>\n",
       "      <td>Discover our stunning collection of 17 gorgeo...</td>\n",
       "      <td>\"This unisex chequered Arab Arafat s...</td>\n",
       "      <td>B</td>\n",
       "      <td>Both responses are well-written and capture th...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>ASICS Women's Performance Running Capri Tight</td>\n",
       "      <td>Unleash your athletic potential with our ASIC...</td>\n",
       "      <td>ASICS Women's Performance Running Ca...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (B) is grounded and fully answers the...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>City Hunter Soft Nylon Russian/Trapper/Trooper...</td>\n",
       "      <td>Stay warm and protected from the harsh winter...</td>\n",
       "      <td>City Hunter Soft Nylon Russian/Trapp...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (A) is well-written and provides addi...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>\\n        You are a leading digital marketer w...</td>\n",
       "      <td>(6249-2) Smart Satin Evening Suit with Flute S...</td>\n",
       "      <td>Indulge in timeless elegance with our exquisi...</td>\n",
       "      <td>Smart Satin Evening Suit with Flute ...</td>\n",
       "      <td>A</td>\n",
       "      <td>Response (A) is a well-written product descrip...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n        You are a leading digital marketer w...   \n",
       "1  \\n        You are a leading digital marketer w...   \n",
       "2  \\n        You are a leading digital marketer w...   \n",
       "3  \\n        You are a leading digital marketer w...   \n",
       "4  \\n        You are a leading digital marketer w...   \n",
       "\n",
       "                               inference_instruction  \\\n",
       "0  \\n        You are a leading digital marketer w...   \n",
       "1  \\n        You are a leading digital marketer w...   \n",
       "2  \\n        You are a leading digital marketer w...   \n",
       "3  \\n        You are a leading digital marketer w...   \n",
       "4  \\n        You are a leading digital marketer w...   \n",
       "\n",
       "                                   inference_context  \\\n",
       "0               Nautica Men's Castaway Stripe Hoodie   \n",
       "1  Unisex Chequered Arab Arafat Shemagh Kafiyah D...   \n",
       "2      ASICS Women's Performance Running Capri Tight   \n",
       "3  City Hunter Soft Nylon Russian/Trapper/Trooper...   \n",
       "4  (6249-2) Smart Satin Evening Suit with Flute S...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0   Slip into effortless style with our Nautica M...   \n",
       "1   Discover our stunning collection of 17 gorgeo...   \n",
       "2   Unleash your athletic potential with our ASIC...   \n",
       "3   Stay warm and protected from the harsh winter...   \n",
       "4   Indulge in timeless elegance with our exquisi...   \n",
       "\n",
       "                                          response_b choice  \\\n",
       "0            \"Nautica Men's Castaway Stripe Hoodi...      A   \n",
       "1            \"This unisex chequered Arab Arafat s...      B   \n",
       "2            ASICS Women's Performance Running Ca...      A   \n",
       "3            City Hunter Soft Nylon Russian/Trapp...      A   \n",
       "4            Smart Satin Evening Suit with Flute ...      A   \n",
       "\n",
       "                                         explanation  confidence  \\\n",
       "0  Response (B) is a repetition of the input desc...           1   \n",
       "1  Both responses are well-written and capture th...           1   \n",
       "2  Response (B) is grounded and fully answers the...           1   \n",
       "3  Response (A) is well-written and provides addi...           1   \n",
       "4  Response (A) is a well-written product descrip...           1   \n",
       "\n",
       "  human_preference  \n",
       "0                A  \n",
       "1                A  \n",
       "2                A  \n",
       "3                A  \n",
       "4                A  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for details in job.task_details:\n",
    "    if details.task_name == \"online-evaluation-pairwise\":\n",
    "        break\n",
    "\n",
    "# Judgments\n",
    "judgements_uri = details.outputs[\"judgments\"].artifacts[0].uri\n",
    "judgements_df = pd.read_json(judgements_uri, lines=True)\n",
    "judgements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cd45f2b-3480-47be-9e74-cf6ed493cc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>autosxs_model_a_win_rate</th>\n",
       "      <th>autosxs_model_b_win_rate</th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>f1</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>human_preference_model_a_win_rate</th>\n",
       "      <th>human_preference_model_b_win_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  autosxs_model_a_win_rate  autosxs_model_b_win_rate  cohens_kappa  \\\n",
       "0       0.9                       0.9                       0.1           0.0   \n",
       "\n",
       "         f1   fn   fp  human_preference_model_a_win_rate  \\\n",
       "0  0.947368  1.0  0.0                                1.0   \n",
       "\n",
       "   human_preference_model_b_win_rate  precision  recall   tn   tp  \n",
       "0                                0.0        1.0     0.9  0.0  9.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate Metrics\n",
    "for details in job.task_details:   #full job details\n",
    "    if details.task_name == \"model-evaluation-text-generation-pairwise\":\n",
    "        break\n",
    "pd.DataFrame([details.outputs[\"autosxs_metrics\"].artifacts[0].metadata])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141f02f-89dc-46bd-9fdc-d87ce8b17083",
   "metadata": {},
   "source": [
    "## Downstream retuning of incumbent model\n",
    "\n",
    "Based on evaluation results, the model can be fine-tuned to improve performance.\n",
    "\n",
    "Reference notebook for fine tuning Gemma from the Google Cloud repository: [model_garden_gemma_finetuning_on_vertex.ipynb](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_finetuning_on_vertex.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4473c-db17-498b-bbf1-0b8a43270951",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean-up\n",
    "\n",
    "* Undeploy and delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd648204-385c-4921-b3b9-0d3009f1883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n",
      "Undeploy Endpoint model backing LRO: projects/757654702990/locations/us-central1/endpoints/7117910623756746752/operations/423810639576694784\n",
      "Endpoint model undeployed. Resource name: projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n",
      "Deleting Endpoint : projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n",
      "Delete Endpoint  backing LRO: projects/757654702990/locations/us-central1/operations/1335789564119220224\n",
      "Endpoint deleted. . Resource name: projects/757654702990/locations/us-central1/endpoints/7117910623756746752\n"
     ]
    }
   ],
   "source": [
    "# Undeploy model and delete endpoint\n",
    "endpoint_vllm.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c31081-5d9c-41f4-80a0-925f6d7acf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
